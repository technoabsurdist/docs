---
title: "Documentation"
description: "chisel lets you profile your inference workloads on cloud GPUs without any infrastructure setup."
---

## Quick Start

Get GPU acceleration in 3 steps:

<Steps>
<Step title="Install">
```bash
pip install chisel-cli
```
</Step>

<Step title="Create your script">
```python my_script.py
from chisel import ChiselApp, GPUType

# here we're choosing 1xA100-80GB
# go to /configuration to learn about GPU types
app = ChiselApp("my-app", gpu=GPUType.A100_80GB_1)

@app.capture_trace(trace_name="gpu_task")
def gpu_function():
    import torch
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Your GPU code here
    x = torch.randn(1000, 1000, device=device)
    y = torch.randn(1000, 1000, device=device)
    return torch.mm(x, y).cpu().numpy()

if __name__ == "__main__":
    result = gpu_function()
    print(f"Result shape: {result.shape}")
```
</Step>

<Step title="Run on GPU">
```bash
# Local execution (CPU)
# executes locally, not using chisel
python my_script.py

# Cloud GPU execution
# executes on cloud GPU, using chisel
chisel python my_script.py
```

<Check>
First run opens browser for authentication, then your code runs on A100 GPUs automatically.
</Check>
</Step>
</Steps>

## GPU Options

| Type | GPUs | Memory | Best For |
| --- | --- | --- | --- |
| `GPUType.A100_80GB_1` | 1x A100 | 80GB | Development, inference |
| `GPUType.A100_80GB_2` | 2x A100 | 160GB | Medium training |
| `GPUType.A100_80GB_4` | 4x A100 | 320GB | Large models |
| `GPUType.A100_80GB_8` | 8x A100 | 640GB | Massive models |

## Documentation

<CardGroup cols={2}>
<Card title="Complete Guide" icon="book-open" href="/quickstart">
  Detailed setup and examples
</Card>

<Card title="API Reference" icon="code" href="/api-reference/introduction">
  Complete API documentation
</Card>

<Card title="Examples" icon="rocket" href="/examples">
  PyTorch, data processing, multi-GPU
</Card>

<Card title="Troubleshooting" icon="wrench" href="/troubleshooting">
  Common issues and solutions
</Card>
</CardGroup>

## Support

- üìß **Email**: [contact@herdora.com](mailto:contact@herdora.com)
- üêõ **Issues**: [GitHub Issues](https://github.com/Herdora/chisel/issues)
- üìñ **Source**: [GitHub Repository](https://github.com/Herdora/chisel)
